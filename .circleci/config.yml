version: 2.1

parameters:
  default_docker_image:
    type: string
    default: cimg/base:2024.01
  base_image:
    type: string
    default: default
  # The dispatch parameters are used to manually dispatch pipelines that normally only run post-merge on develop
  # from the CircleCI UI. Example configuration:
  #   when:
  #     or:
  #       - equal: [ "develop", <<pipeline.git.branch>> ]
  #       - equal: [ true, <<pipeline.parameters.main_dispatch>> ]
  # Add a new `*_dispatch` parameter for any pipeline you want manual dispatch for.
  main_dispatch:
    type: boolean
    default: true # default to running main in case the manual run cancelled an automatic run
  fault_proofs_dispatch:
    type: boolean
    default: false
  reproducibility_dispatch:
    type: boolean
    default: false
  diff_asterisc_bytecode_dispatch:
    type: boolean
    default: false
  kontrol_dispatch:
    type: boolean
    default: false
  cannon_full_test_dispatch:
    type: boolean
    default: false
  sdk_dispatch:
    type: boolean
    default: false
  docker_publish_dispatch:
    type: boolean
    default: false
  publish_contract_artifacts_dispatch:
    type: boolean
    default: false
  stale_check_dispatch:
    type: boolean
    default: false
  contracts_coverage_dispatch:
    type: boolean
    default: false
  heavy_fuzz_dispatch:
    type: boolean
    default: false
  acceptance_tests_dispatch:
    type: boolean
    default: false
  kurtosis_acceptance_tests_dispatch:
    type: boolean
    default: false
  sync_test_op_node_dispatch:
    type: boolean
    default: false
  ai_contracts_test_dispatch:
    type: boolean
    default: false
  github-event-type:
    type: string
    default: "__not_set__"
  github-event-action:
    type: string
    default: "__not_set__"
  github-event-base64:
    type: string
    default: "__not_set__"
  devnet-metrics-collect:
    type: boolean
    default: false
  flake-shake-dispatch:
    type: boolean
    default: false
  flake-shake-iterations:
    type: integer
    default: 200
  flake-shake-workers:
    type: integer
    default: 10

orbs:
  go: circleci/go@1.8.0
  gcp-cli: circleci/gcp-cli@3.0.1
  slack: circleci/slack@6.0.0
  shellcheck: circleci/shellcheck@3.2.0
  codecov: codecov/codecov@5.0.3
  utils: ethereum-optimism/circleci-utils@1.0.20
  docker: circleci/docker@2.8.2
  github-cli: circleci/github-cli@2.7.0

commands:
  gcp-oidc-authenticate:
    description: "Authenticate with GCP using a CircleCI OIDC token."
    parameters:
      project_id:
        type: env_var_name
        default: GCP_PROJECT_ID
      workload_identity_pool_id:
        type: env_var_name
        default: GCP_WIP_ID
      workload_identity_pool_provider_id:
        type: env_var_name
        default: GCP_WIP_PROVIDER_ID
      service_account_email:
        type: env_var_name
        default: GCP_SERVICE_ACCOUNT_EMAIL
      gcp_cred_config_file_path:
        type: string
        default: /home/circleci/gcp_cred_config.json
      oidc_token_file_path:
        type: string
        default: /home/circleci/oidc_token.json
    steps:
      - run:
          name: "Create OIDC credential configuration"
          command: |
            # Store OIDC token in temp file
            echo $CIRCLE_OIDC_TOKEN > << parameters.oidc_token_file_path >>
            # Create a credential configuration for the generated OIDC ID Token
            gcloud iam workload-identity-pools create-cred-config \
                "projects/${<< parameters.project_id >>}/locations/global/workloadIdentityPools/${<< parameters.workload_identity_pool_id >>}/providers/${<< parameters.workload_identity_pool_provider_id >>}"\
                --output-file="<< parameters.gcp_cred_config_file_path >>" \
                --service-account="${<< parameters.service_account_email >>}" \
                --credential-source-file=<< parameters.oidc_token_file_path >>
      - run:
          name: "Authenticate with GCP using OIDC"
          command: |
            # Configure gcloud to leverage the generated credential configuration
            gcloud auth login --brief --cred-file "<< parameters.gcp_cred_config_file_path >>"
            # Configure ADC
            echo "export GOOGLE_APPLICATION_CREDENTIALS='<< parameters.gcp_cred_config_file_path >>'" | tee -a "$BASH_ENV"

  check-changed:
    description: "Conditionally halts a step if certain modules change"
    parameters:
      patterns:
        type: string
        description: "Comma-separated list of dependencies"
      no_go_deps:
        type: string
        default: ""
        description: "If set, does not trigger on `go.mod` / `go.sum` changes."
    steps:
      - run:
          name: "Check for changes"
          environment:
            CHECK_CHANGED_NO_GO_DEPS: "<<parameters.no_go_deps>>"
          command: |
            cd ops/check-changed
            pip3 install -r requirements.txt
            python3 main.py "<<parameters.patterns>>"

  install-contracts-dependencies:
    description: "Install the dependencies for the smart contracts"
    parameters:
      solc_versions:
        description: "The versions of solc to install"
        type: string
        default: "0.8.15,0.8.19,0.8.25,0.8.28"
    steps:
      - restore_cache:
          keys:
            # use mise.toml to anchor on the underlying forge/svm versions
            - svm-cache-{{ checksum "mise.toml" }}-<<parameters.solc_versions>>
      - run:
          name: Install solc compilers
          command: |
            for version in $(echo "<<parameters.solc_versions>>" | tr ',' '\n'); do
              svm which $version || svm install $version
            done
      - save_cache:
          key: svm-cache-{{ checksum "mise.toml" }}-<<parameters.solc_versions>>
          paths:
            - ~/.svm
      - run:
          name: Install dependencies
          command: |
            # Manually craft the submodule update command in order to take advantage
            # of the -j parameter, which speeds it up a lot.
            git submodule update --init --recursive --force -j 8
          working_directory: packages/contracts-bedrock

  # Notifies us on Slack a build fails on develop
  notify-failures-on-develop:
    description: "Notify Slack"
    parameters:
      channel:
        type: string
        default: C03N11M0BBN
      mentions:
        type: string
        default: ""
    steps:
      - slack/notify:
          channel: << parameters.channel >>
          event: fail
          template: basic_fail_1
          branch_pattern: develop
          mentions: "<< parameters.mentions >>"

  # Notifies us on Discord when a build fails on develop
  # For Discord to properly trigger notifications, mentions need to be in the format:
  # User mentions: <@USER_ID>
  # Role mentions: <@&ROLE_ID>
  # Example: <@&1346448413172170807> is how we'd tag the Protocol DevX Pod
  discord-notification-failures-on-develop:
    description: "Notify Discord"
    parameters:
      message:
        type: string
        default: ""
      mentions:
        type: string
        default: ""
    steps:
      - run:
          name: "Notify Discord"
          command: |
            if [ "${CIRCLE_BRANCH}" == "develop" ]; then
              # Format message for Discord with better structure and formatting
              DISCORD_MESSAGE="ðŸš¨ **CI Failure Detected** ðŸš¨\n"
              DISCORD_MESSAGE="${DISCORD_MESSAGE}> **Repository:** \`${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}\`\n"
              DISCORD_MESSAGE="${DISCORD_MESSAGE}> **Branch:** \`${CIRCLE_BRANCH}\`\n"
              DISCORD_MESSAGE="${DISCORD_MESSAGE}> **Job:** \`${CIRCLE_JOB}\`\n"
              DISCORD_MESSAGE="${DISCORD_MESSAGE}> **Build Link:** ${CIRCLE_BUILD_URL}"

              # Add failure reason if provided
              if [ ! -z "<< parameters.message >>" ]; then
                DISCORD_MESSAGE="${DISCORD_MESSAGE}\n\n**Failure message:** << parameters.message >>"
              fi

              # Add mentions if provided
              if [ ! -z "<< parameters.mentions >>" ]; then
                DISCORD_MESSAGE="${DISCORD_MESSAGE}\n\n**Attention:** << parameters.mentions >>"
              fi

              # Add extra mentions from environment (e.g. owners from flake-shake)
              if [ -n "${EXTRA_DISCORD_MENTIONS:-}" ]; then
                DISCORD_MESSAGE="${DISCORD_MESSAGE}\n\n**Owners:** ${EXTRA_DISCORD_MENTIONS}"
              fi

              # Post to Discord webhook
              curl -X POST -H "Content-Type: application/json" \
                -d "{\"content\": \"${DISCORD_MESSAGE}\"}" "${notify_ci}"
            fi
          when: on_fail

  get-target-branch:
    description: "Determine the PR target branch and export TARGET_BRANCH for subsequent steps"
    steps:
      - run:
          name: Determine target branch for this pipeline
          command: |
            TARGET_BRANCH=""
            if [ -n "${CIRCLE_PULL_REQUEST:-}" ]; then
              TARGET_BRANCH=$(curl -s "https://api.github.com/repos/${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}/pulls/${CIRCLE_PULL_REQUEST##*/}" | jq -r .base.ref)
            fi

            # Fallbacks when not a PR or API did not return a branch
            if [ -z "$TARGET_BRANCH" ] || [ "$TARGET_BRANCH" = "null" ]; then
              TARGET_BRANCH="<< pipeline.git.branch >>"
            fi

            echo "Resolved TARGET_BRANCH=$TARGET_BRANCH"
            echo "export TARGET_BRANCH=$TARGET_BRANCH" >> "$BASH_ENV"

  setup-dev-features:
    description: "Set up dev feature environment variables from comma-separated list"
    parameters:
      dev_features:
        description: "Comma-separated list of dev features to enable"
        type: string
        default: ""
    steps:
      - run:
          name: Set dev feature environment variables
          command: |
            # Set dev feature environment variables if provided
            if [ -n "<<parameters.dev_features>>" ]; then
              DEV_FEATURES_STRING="<<parameters.dev_features>>"

              # Check if this is just "main" (baseline with no dev features)
              if [ "$(echo "$DEV_FEATURES_STRING" | tr '[:upper:]' '[:lower:]')" = "main" ]; then
                echo "Running with baseline configuration (no dev features enabled)"
              else
                echo "Enabling dev features: <<parameters.dev_features>>"
                IFS=','
                for feature in $DEV_FEATURES_STRING; do
                  feature=$(echo "$feature" | xargs)  # trim whitespace
                  if [ -n "$feature" ] && [ "$(echo "$feature" | tr '[:upper:]' '[:lower:]')" != "main" ]; then
                    env_var="DEV_FEATURE__${feature}"
                    echo "Setting ${env_var}=true"
                    echo "export ${env_var}=true" >> $BASH_ENV
                  fi
                done
                unset IFS
              fi
            fi

  run-contracts-check:
    parameters:
      command:
        description: Just command that runs the check
        type: string
    steps:
      - run:
          name: <<parameters.command>>
          command: |
            git reset --hard
            git clean -df
            just <<parameters.command>>
            git status --porcelain
            [ -z "$(git status --porcelain)" ] || exit 1
          working_directory: packages/contracts-bedrock
          when: always
          environment:
            FOUNDRY_PROFILE: ci

  checkout-from-workspace:
    steps:
      - attach_workspace:
          at: "."
      - utils/install-mise

jobs:
  # Kurtosis-based acceptance tests
  op-acceptance-tests-kurtosis:
    parameters:
      devnet:
        description: |
          The name of the pre-defined Kurtosis devnet to run the acceptance tests against
          (e.g. 'simple', 'interop', 'jovian'). Empty string uses in-process testing (sysgo orchestrator).
        type: string
        default: "interop"
      gate:
        description: The gate to run the acceptance tests against. Must be defined in op-acceptance-tests/acceptance-tests.yaml.
        type: string
        default: "interop"
      no_output_timeout:
        description: Timeout for when CircleCI kills the job if there's no output
        type: string
        default: 30m
      use_circleci_runner:
        description: Whether to use CircleCI runners (with Docker) instead of self-hosted runners
        type: boolean
        default: false
    machine:
      image: <<# parameters.use_circleci_runner >>ubuntu-2404:current<</ parameters.use_circleci_runner >><<^ parameters.use_circleci_runner >>true<</ parameters.use_circleci_runner >>
      docker_layer_caching: <<parameters.use_circleci_runner>>
    resource_class: <<# parameters.use_circleci_runner >>xlarge<</ parameters.use_circleci_runner >><<^ parameters.use_circleci_runner >>ethereum-optimism/latitude-1<</ parameters.use_circleci_runner >>
    steps:
      - checkout-from-workspace
      - run:
          name: Lint/Vet/Build op-acceptance-tests/cmd
          working_directory: op-acceptance-tests
          command: |
            just cmd-check
      - run:
          name: Setup Kurtosis
          command: |
            echo "Setting up Kurtosis for external devnet testing..."
            echo "Using Kurtosis from: $(which kurtosis || echo 'not found')"
            kurtosis version || true
            echo "Starting Kurtosis engine..."
            kurtosis engine start || true
            echo "Cleaning old instances..."
            kurtosis clean -a || true
            kurtosis engine status || true
            echo "Kurtosis setup complete"
      - run:
          name: Dump kurtosis logs (pre-run)
          command: |
            # Best-effort: show engine status and existing enclaves before the test run
            kurtosis engine status || true
            kurtosis enclave ls || true
      - run:
          name: Run acceptance tests (devnet=<<parameters.devnet>>, gate=<<parameters.gate>>)
          working_directory: op-acceptance-tests
          no_output_timeout: 1h
          environment:
            GOFLAGS: "-mod=mod"
            GO111MODULE: "on"
            GOGC: "0"
          command: |
            LOG_LEVEL=info just acceptance-test "<<parameters.devnet>>" "<<parameters.gate>>"
      - run:
          name: Dump kurtosis logs
          when: on_fail
          command: |
            # Dump logs & specs
            kurtosis dump ./.kurtosis-dump

            # Remove spec.json files
            rm -rf ./.kurtosis-dump/enclaves/**/*.json

            # Remove all unnecessary logs
            rm -rf ./.kurtosis-dump/enclaves/*/kurtosis-api--*
            rm -rf ./.kurtosis-dump/enclaves/*/kurtosis-logs-collector--*
            rm -rf ./.kurtosis-dump/enclaves/*/task-*

            # Print enclaves and try to show service logs for the most recent devnet
            kurtosis enclave ls || true
            # Dump logs for all enclaves to aid debugging
            for e in $(kurtosis enclave ls --output json 2>/dev/null | jq -r '.[].identifier' 2>/dev/null); do
              echo "\n==== Kurtosis logs for enclave: $e ===="
              kurtosis enclave inspect "$e" || true
              kurtosis service logs "$e" --all-services --follow=false || true
            done
      - run:
          name: Print results (summary)
          working_directory: op-acceptance-tests
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            cat "$LOG_DIR/summary.log" || true
      - run:
          name: Print results (failures)
          working_directory: op-acceptance-tests
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            cat "$LOG_DIR/failed/*.log" || true
          when: on_fail
      - run:
          name: Print results (all)
          working_directory: op-acceptance-tests
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            cat "$LOG_DIR/all.log" || true
      - run:
          name: Generate JUnit XML test report for CircleCI
          working_directory: op-acceptance-tests
          when: always
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            gotestsum --junitfile results/results.xml --raw-command cat $LOG_DIR/raw_go_events.log || true
      - when:
          condition: always
          steps:
            - store_test_results:
                path: ./op-acceptance-tests/results
      - when:
          condition: always
          steps:
            - store_artifacts:
                path: ./op-acceptance-tests/logs
      - discord-notification-failures-on-develop:
          mentions: "Platforms (<@&1346448413172170807>)" # Protocol DevX Pod
          message: "Kurtosis acceptance tests failed for devnet <<parameters.devnet>> gate <<parameters.gate>>"
  initialize:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: large
    steps:
      - utils/checkout-with-mise
      - install-contracts-dependencies
      - persist_to_workspace:
          root: "."
          paths:
            - "."

  cannon-go-lint-and-test:
    machine: true
    resource_class: ethereum-optimism/latitude-1
    parameters:
      skip_slow_tests:
        type: boolean
        default: false
      no_output_timeout:
        description: Timeout for when CircleCI kills the job if there's no output
        type: string
        default: 10m
      notify:
        description: Whether to notify on failure
        type: boolean
        default: false
    steps:
      - checkout-from-workspace
      - check-changed:
          patterns: cannon,packages/contracts-bedrock/src/cannon,op-preimage,go.mod
      - run:
          name: prep Cannon results dir
          command: |
            mkdir -p ./tmp/test-results
            mkdir -p ./tmp/testlogs
      - run:
          name: build Cannon example binaries
          command: make elf # only compile ELF binaries with Go, we do not have MIPS GCC for creating the debug-dumps.
          working_directory: cannon/testdata
      - run:
          name: Cannon Go lint
          command: |
            make lint
          working_directory: cannon
      - run:
          name: Cannon Go 64-bit tests
          no_output_timeout: <<parameters.no_output_timeout>>
          command: |
            export SKIP_SLOW_TESTS="<<parameters.skip_slow_tests>>"
            TIMEOUT="10m"
            if [ "$SKIP_SLOW_TESTS" = "false" ]; then
              TIMEOUT="45m"
            fi
            gotestsum --format=testname --junitfile=../tmp/test-results/cannon-64.xml --jsonfile=../tmp/testlogs/log-64.json \
            -- -timeout=$TIMEOUT -parallel=$(nproc) -coverpkg=github.com/ethereum-optimism/optimism/cannon/... -coverprofile=coverage-64.out ./...
          working_directory: cannon
      - codecov/upload:
          disable_search: true
          files: ./cannon/coverage-64.out
          flags: cannon-go-tests-64
      - store_test_results:
          path: ./tmp/test-results
      - store_artifacts:
          path: ./tmp/testlogs
          when: always
      - when:
          condition: <<parameters.notify>>
          steps:
            - notify-failures-on-develop:
                mentions: "@proofs-team"

  diff-asterisc-bytecode:
    machine: true
    resource_class: ethereum-optimism/latitude-1
    steps:
      - checkout-from-workspace
      - run:
          name: Check `RISCV.sol` bytecode
          working_directory: packages/contracts-bedrock
          command: |
            # Clone asterisc @ the pinned version to fetch remote `RISCV.sol`
            ASTERISC_REV="v$(yq '.tools.asterisc' ../../mise.toml)"
            REMOTE_ASTERISC_PATH="./src/vendor/asterisc/RISCV_Remote.sol"
            git clone https://github.com/ethereum-optimism/asterisc \
              -b $ASTERISC_REV && \
              cp ./asterisc/rvsol/src/RISCV.sol $REMOTE_ASTERISC_PATH

            # Replace import paths
            sed -i -e 's/@optimism\///' $REMOTE_ASTERISC_PATH
            # Replace legacy interface paths
            sed -i -e 's/src\/cannon\/interfaces\//interfaces\/cannon\//g' $REMOTE_ASTERISC_PATH
            sed -i -e 's/src\/dispute\/interfaces\//interfaces\/dispute\//g' $REMOTE_ASTERISC_PATH
            # Replace contract name
            sed -i -e 's/contract RISCV/contract RISCV_Remote/' $REMOTE_ASTERISC_PATH

            # Install deps
            forge install

            # Diff bytecode, with both contracts compiled in the local environment.
            REMOTE_ASTERISC_CODE="$(forge inspect RISCV_Remote bytecode | tr -d '\n')"
            LOCAL_ASTERISC_CODE="$(forge inspect RISCV bytecode | tr -d '\n')"
            if [ "$REMOTE_ASTERISC_CODE" != "$LOCAL_ASTERISC_CODE" ]; then
              echo "Asterisc bytecode mismatch. Local version does not match remote. Diff:"
              diff <(echo "$REMOTE_ASTERISC_CODE") <(echo "$LOCAL_ASTERISC_CODE")
            else
              echo "Asterisc version up to date."
            fi
      - notify-failures-on-develop:
          mentions: "@clabby @proofs-team"

  contracts-bedrock-build:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: xlarge
    parameters:
      build_args:
        description: Forge build arguments
        type: string
        default: ""
      profile:
        description: Profile to use for building
        type: string
        default: ci
    steps:
      - checkout-from-workspace
      - run:
          name: Print forge version
          command: forge --version
      - run:
          name: Pull artifacts
          command: bash scripts/ops/pull-artifacts.sh
          working_directory: packages/contracts-bedrock
      - run:
          name: Build contracts
          command: forge build <<parameters.build_args>>
          environment:
            FOUNDRY_PROFILE: <<parameters.profile>>
          working_directory: packages/contracts-bedrock
      - run:
          name: "Copy artifacts into deployer"
          command: |
            just copy-contract-artifacts
          working_directory: op-deployer
      - persist_to_workspace:
          root: "."
          paths:
            - "packages/contracts-bedrock/cache"
            - "packages/contracts-bedrock/artifacts"
            - "packages/contracts-bedrock/forge-artifacts"
            - "op-deployer/pkg/deployer/artifacts/forge-artifacts"
      - notify-failures-on-develop

  check-kontrol-build:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: xlarge
    steps:
      - utils/checkout-with-mise
      - attach_workspace: { at: "." }
      - install-contracts-dependencies
      - check-changed:
          patterns: contracts-bedrock
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Run Kontrol build
          command: just kontrol-summary-full
          working_directory: packages/contracts-bedrock
      - run:
          name: Build Kontrol summary files
          command: forge build ./test/kontrol/proofs
          working_directory: packages/contracts-bedrock
      - notify-failures-on-develop

  docker-build:
    environment:
      DOCKER_BUILDKIT: 1
    parameters:
      docker_tags:
        description: Docker image tags, comma-separated
        type: string
      docker_name:
        description: "Docker buildx bake target"
        type: string
        default: ""
      registry:
        description: Docker registry
        type: string
        default: "us-docker.pkg.dev"
      repo:
        description: Docker repo
        type: string
        default: "oplabs-tools-artifacts/images"
      save_image_tag:
        description: Save docker image with given tag
        type: string
        default: ""
      platforms:
        description: Platforms to build for, comma-separated
        type: string
        default: "linux/amd64"
      publish:
        description: Publish the docker image (multi-platform, all tags)
        type: boolean
        default: false
      release:
        description: Run the release script
        type: boolean
        default: false
      resource_class:
        description: Docker resource class
        type: string
        default: medium
    machine:
      image: <<pipeline.parameters.base_image>>
      resource_class: "<<parameters.resource_class>>"
      docker_layer_caching: true # we rely on this for faster builds, and actively warm it up for builds with common stages
    steps:
      - checkout-from-workspace
      - run:
          command: mkdir -p /tmp/docker_images
      - when:
          condition:
            or:
              - "<<parameters.publish>>"
              - "<<parameters.release>>"
          steps:
            - gcp-cli/install
      - when:
          condition:
            or:
              - "<<parameters.publish>>"
              - "<<parameters.release>>"
          steps:
            - gcp-oidc-authenticate
      - run:
          name: Build
          command: |
            # Check to see if DOCKER_HUB_READ_ONLY_TOKEN is set (i.e. we are in repo) before attempting to use secrets.
            # Building should work without this read only login, but may get rate limited.
            if [[ -v DOCKER_HUB_READ_ONLY_TOKEN ]]; then
              echo "$DOCKER_HUB_READ_ONLY_TOKEN" | docker login -u "$DOCKER_HUB_READ_ONLY_USER" --password-stdin
            fi

            export REGISTRY="<<parameters.registry>>"
            export REPOSITORY="<<parameters.repo>>"
            export IMAGE_TAGS="$(echo -ne "<<parameters.docker_tags>>" | sed "s/[^a-zA-Z0-9\n,]/-/g")"
            export GIT_COMMIT="$(git rev-parse HEAD)"
            export GIT_DATE="$(git show -s --format='%ct')"
            export PLATFORMS="<<parameters.platforms>>"

            echo "Checking git tags pointing at $GIT_COMMIT:"
            tags_at_commit=$(git tag --points-at $GIT_COMMIT)
            echo "Tags at commit:\n$tags_at_commit"

            filtered_tags=$(echo "$tags_at_commit" | grep "^<<parameters.docker_name>>/" || true)
            echo "Filtered tags: $filtered_tags"

            if [ -z "$filtered_tags" ]; then
              export GIT_VERSION="untagged"
            else
              sorted_tags=$(echo "$filtered_tags" | sed "s/<<parameters.docker_name>>\///" | sort -V)
              echo "Sorted tags: $sorted_tags"

              # prefer full release tag over "-rc" release candidate tag if both exist
              full_release_tag=$(echo "$sorted_tags" | grep -v -- "-rc" || true)
              if [ -z "$full_release_tag" ]; then
                export GIT_VERSION=$(echo "$sorted_tags" | tail -n 1)
              else
                export GIT_VERSION=$(echo "$full_release_tag" | tail -n 1)
              fi
            fi

            echo "Setting GIT_VERSION=$GIT_VERSION"

            # Create, start (bootstrap) and use a *named* docker builder
            # This allows us to cross-build multi-platform,
            # and naming allows us to use the DLC (docker-layer-cache)
            docker buildx create --driver=docker-container --name=buildx-build --bootstrap --use

            DOCKER_OUTPUT_DESTINATION=""
            if [ "<<parameters.publish>>" == "true" ]; then
              gcloud auth configure-docker <<parameters.registry>>
              echo "Building for platforms $PLATFORMS and then publishing to registry"
              DOCKER_OUTPUT_DESTINATION="--push"
              if [ "<<parameters.save_image_tag>>" != "" ]; then
                echo "ERROR: cannot save image to docker when publishing to registry"
                exit 1
              fi
            else
              if [ "<<parameters.save_image_tag>>" == "" ]; then
                echo "Running $PLATFORMS build without destination (cache warm-up)"
                DOCKER_OUTPUT_DESTINATION=""
              elif [[ $PLATFORMS == *,* ]]; then
                echo "ERROR: cannot perform multi-arch (platforms: $PLATFORMS) build while also loading the result into regular docker"
                exit 1
              else
                echo "Running single-platform $PLATFORMS build and loading into docker"
                DOCKER_OUTPUT_DESTINATION="--load"
              fi
            fi

            # Let them cook!
            docker buildx bake \
              --progress plain \
              --builder=buildx-build \
              -f docker-bake.hcl \
              $DOCKER_OUTPUT_DESTINATION \
              <<parameters.docker_name>>

          no_output_timeout: 45m
      - when:
          condition: "<<parameters.publish>>"
          steps:
            - notify-failures-on-develop
      - when:
          condition: "<<parameters.save_image_tag>>"
          steps:
            - run:
                name: Save
                command: |
                  IMAGE_NAME="<<parameters.registry>>/<<parameters.repo>>/<<parameters.docker_name>>:<<parameters.save_image_tag>>"
                  docker save -o /tmp/docker_images/<<parameters.docker_name>>.tar $IMAGE_NAME
            - persist_to_workspace:
                root: /tmp/docker_images
                paths: # only write the one file, to avoid concurrent workspace-file additions
                  - "<<parameters.docker_name>>.tar"
      - when:
          condition: "<<parameters.release>>"
          steps:
            - run:
                name: Tag
                command: |
                  ./ops/scripts/ci-docker-tag-op-stack-release.sh <<parameters.registry>>/<<parameters.repo>> $CIRCLE_TAG $CIRCLE_SHA1
      - when:
          condition:
            or:
              - and:
                  - "<<parameters.publish>>"
                  - "<<parameters.release>>"
              - and:
                  - "<<parameters.publish>>"
                  - equal: [develop, << pipeline.git.branch >>]
          steps:
            - gcp-oidc-authenticate:
                service_account_email: GCP_SERVICE_ATTESTOR_ACCOUNT_EMAIL
            - run:
                name: Sign
                command: |
                  VER=$(yq '.tools.binary_signer' mise.toml)
                  wget -O - "https://github.com/ethereum-optimism/binary_signer/archive/refs/tags/v${VER}.tar.gz" | tar xz
                  cd "binary_signer-${VER}/signer"

                  IMAGE_PATH="<<parameters.registry>>/<<parameters.repo>>/<<parameters.docker_name>>:<<pipeline.git.revision>>"
                  echo $IMAGE_PATH
                  pip3 install -r requirements.txt

                  python3 ./sign_image.py --command="sign"\
                      --attestor-project-name="$ATTESTOR_PROJECT_NAME"\
                      --attestor-name="$ATTESTOR_NAME"\
                      --image-path="$IMAGE_PATH"\
                      --signer-logging-level="INFO"\
                      --attestor-key-id="//cloudkms.googleapis.com/v1/projects/$ATTESTOR_PROJECT_NAME/locations/global/keyRings/$ATTESTOR_NAME-key-ring/cryptoKeys/$ATTESTOR_NAME-key/cryptoKeyVersions/1"

  # Verify newly published images (built on AMD machine) will run on ARM
  check-cross-platform:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: arm.medium
    parameters:
      registry:
        description: Docker registry
        type: string
        default: "us-docker.pkg.dev"
      repo:
        description: Docker repo
        type: string
        default: "oplabs-tools-artifacts/images"
      op_component:
        description: "Name of op-stack component (e.g. op-node)"
        type: string
        default: ""
      docker_tag:
        description: "Tag of docker image"
        type: string
        default: "<<pipeline.git.revision>>"
    steps:
      - setup_remote_docker
      - run:
          name: "Verify Image Platform"
          command: |
            image_name="<<parameters.registry>>/<<parameters.repo>>/<<parameters.op_component>>:<<parameters.docker_tag>>"
            echo "Retrieving Docker image manifest: $image_name"
            MANIFEST=$(docker manifest inspect $image_name)

            echo "Verifying 'linux/arm64' is supported..."
            SUPPORTED_PLATFORM=$(echo "$MANIFEST" | jq -r '.manifests[] | select(.platform.architecture == "arm64" and .platform.os == "linux")')
            echo $SUPPORT_PLATFORM
            if [ -z "$SUPPORTED_PLATFORM" ]; then
              echo "Platform 'linux/arm64' not supported by this image"
              exit 1
            fi
      - run:
          name: "Pull and run docker image"
          command: |
            image_name="<<parameters.registry>>/<<parameters.repo>>/<<parameters.op_component>>:<<parameters.docker_tag>>"
            docker pull $image_name || exit 1
            docker run $image_name <<parameters.op_component>> --version || exit 1

  contracts-bedrock-tests:
    circleci_ip_ranges: true
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: xlarge
    parameters:
      test_list:
        description: List of test files to run
        type: string
      test_command:
        description: Test command to execute (test or coverage)
        type: string
        default: test
      test_flags:
        description: Additional flags to pass to the test command
        type: string
        default: ""
      test_timeout:
        description: Timeout for running tests
        type: string
        default: 15m
      test_profile:
        description: Profile to use for testing
        type: string
        default: ci
      check_changed_patterns:
        description: List of changed files to run tests on
        type: string
        default: contracts-bedrock
    steps:
      - checkout-from-workspace
      - run:
          name: Check if test list is empty
          command: |
            TEST_FILES=$(<<parameters.test_list>>)
            if [ -z "$TEST_FILES" ]; then
              echo "No test files to run. Exiting early."
              circleci-agent step halt
            fi
          working_directory: packages/contracts-bedrock
      - check-changed:
          patterns: <<parameters.check_changed_patterns>>
      - run:
          name: Print dependencies
          command: just dep-status
          working_directory: packages/contracts-bedrock
      - run:
          name: Print forge version
          command: forge --version
          working_directory: packages/contracts-bedrock
      - run:
          name: Pull artifacts
          command: bash scripts/ops/pull-artifacts.sh
          working_directory: packages/contracts-bedrock
      - run:
          name: Build go-ffi
          command: just build-go-ffi
          working_directory: packages/contracts-bedrock
      - run:
          name: Run tests
          command: |
            TEST_FILES=$(<<parameters.test_list>>)
            TEST_FILES=$(echo "$TEST_FILES" | circleci tests split --split-by=timings)
            TEST_FILES=$(echo "$TEST_FILES" | sed 's|^test/||')
            MATCH_PATH="./test/{$(echo "$TEST_FILES" | paste -sd "," -)}"
            forge <<parameters.test_command>> <<parameters.test_flags>> --match-path "$MATCH_PATH"
          environment:
            FOUNDRY_PROFILE: <<parameters.test_profile>>
          working_directory: packages/contracts-bedrock
          no_output_timeout: <<parameters.test_timeout>>
      - run:
          name: Print failed test traces
          command: just test-rerun
          environment:
            FOUNDRY_PROFILE: ci
          working_directory: packages/contracts-bedrock
          when: on_fail
      - run:
          name: Lint forge test names
          command: just lint-forge-tests-check-no-build
          working_directory: packages/contracts-bedrock
      - save_cache:
          name: Save Go build cache
          key: golang-build-cache-contracts-bedrock-tests-{{ checksum "go.sum" }}
          paths:
            - "/root/.cache/go-build"
      - notify-failures-on-develop

  contracts-bedrock-heavy-fuzz-nightly:
    circleci_ip_ranges: true
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: xlarge
    steps:
      - checkout-from-workspace
      - run:
          name: Print dependencies
          command: just dep-status
          working_directory: packages/contracts-bedrock
      - run:
          name: Print forge version
          command: forge --version
          working_directory: packages/contracts-bedrock
      - run:
          name: Pull artifacts
          command: bash scripts/ops/pull-artifacts.sh
          working_directory: packages/contracts-bedrock
      - run:
          name: Build go-ffi
          command: just build-go-ffi
          working_directory: packages/contracts-bedrock
      - run:
          name: Run heavy fuzz tests
          command: just test
          environment:
            FOUNDRY_PROFILE: ciheavy
          working_directory: packages/contracts-bedrock
          no_output_timeout: 90m
      - run:
          name: Print failed test traces
          command: just test-rerun
          environment:
            FOUNDRY_PROFILE: ciheavy
          working_directory: packages/contracts-bedrock
          when: on_fail
      - save_cache:
          name: Save Go build cache
          key: golang-build-cache-contracts-bedrock-heavy-fuzz-{{ checksum "go.sum" }}
          paths:
            - "/root/.cache/go-build"
      - notify-failures-on-develop

  # AI Contracts Test Maintenance System
  # Runbook: https://github.com/ethereum-optimism/optimism/blob/develop/ops/ai-eng/contracts-test-maintenance/docs/runbook.md
  ai-contracts-test:
    circleci_ip_ranges: true
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: medium
    steps:
      - checkout-from-workspace
      - run:
          name: Check Python version
          command: python3 --version
      - run:
          name: Run AI Contracts Test System
          command: just ai-contracts-test
          working_directory: ops/ai-eng
          no_output_timeout: 60m
      - store_artifacts:
          path: ops/ai-eng/contracts-test-maintenance/log.json
          destination: log.json
      - notify-failures-on-develop

  contracts-bedrock-coverage:
    circleci_ip_ranges: true
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: 2xlarge
    parameters:
      test_flags:
        description: Additional flags to pass to the test command
        type: string
        default: ""
      test_timeout:
        description: Timeout for running tests
        type: string
        default: 15m
      test_profile:
        description: Profile to use for testing
        type: string
        default: ci
      dev_features:
        description: Comma-separated list of dev features to enable (e.g., "OPTIMISM_PORTAL_INTEROP,ANOTHER_FEATURE")
        type: string
        default: ""
    steps:
      - checkout-from-workspace
      - check-changed:
          patterns: contracts-bedrock
      - run:
          name: Print dependencies
          command: just dep-status
          working_directory: packages/contracts-bedrock
      - run:
          name: Print forge version
          command: forge --version
          working_directory: packages/contracts-bedrock
      - run:
          name: Pull artifacts
          command: bash scripts/ops/pull-artifacts.sh
          working_directory: packages/contracts-bedrock
      - run:
          name: Install lcov
          command: |
            sudo apt-get update
            sudo apt-get install -y lcov
      - run:
          name: Write pinned block number for cache key
          command: |
            just print-pinned-block-number > ./pinnedBlockNumber.txt
            cat pinnedBlockNumber.txt
          working_directory: packages/contracts-bedrock
      - restore_cache:
          name: Restore forked state
          key: forked-state-contracts-bedrock-tests-upgrade-{{ checksum "packages/contracts-bedrock/pinnedBlockNumber.txt" }}
      - setup-dev-features:
          dev_features: <<parameters.dev_features>>
      - run:
          name: Run coverage tests
          command: just coverage-lcov-all <<parameters.test_flags>>
          environment:
            FOUNDRY_PROFILE: <<parameters.test_profile>>
            ETH_RPC_URL: https://ci-mainnet-l1-archive.optimism.io
          working_directory: packages/contracts-bedrock
          no_output_timeout: <<parameters.test_timeout>>
      - run:
          name: Print failed test traces
          command: just test-rerun | tee failed-test-traces.log
          environment:
            FOUNDRY_PROFILE: <<parameters.test_profile>>
            ETH_RPC_URL: https://ci-mainnet-l1-archive.optimism.io
          working_directory: packages/contracts-bedrock
          when: on_fail
      - codecov/upload:
          disable_search: true
          files: ./packages/contracts-bedrock/lcov-all.info
          flags: contracts-bedrock-tests
      - store_artifacts:
          path: packages/contracts-bedrock/failed-test-traces.log
          when: on_fail
      - notify-failures-on-develop

  contracts-bedrock-tests-upgrade:
    circleci_ip_ranges: true
    parameters:
      fork_op_chain:
        description: Fork OP Chain
        type: string
        default: "op"
      fork_base_chain:
        description: Fork Base Chain
        type: string
        default: "mainnet"
      fork_base_rpc:
        description: Fork Base RPC
        type: string
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: xlarge
    steps:
      - checkout-from-workspace
      - check-changed:
          patterns: contracts-bedrock
      - run:
          name: Print dependencies
          command: just dep-status
          working_directory: packages/contracts-bedrock
      - run:
          name: Print forge version
          command: forge --version
          working_directory: packages/contracts-bedrock
      - run:
          name: Pull artifacts
          command: bash scripts/ops/pull-artifacts.sh
          working_directory: packages/contracts-bedrock
      - run:
          name: Write pinned block number for cache key
          command: |
            just print-pinned-block-number > ./pinnedBlockNumber.txt
            cat pinnedBlockNumber.txt
          environment:
            FORK_BASE_CHAIN: <<parameters.fork_base_chain>>
          working_directory: packages/contracts-bedrock
      - restore_cache:
          name: Restore forked state
          key: forked-state-contracts-bedrock-tests-upgrade-<<parameters.fork_op_chain>>-<<parameters.fork_base_chain>>-{{ checksum "packages/contracts-bedrock/pinnedBlockNumber.txt" }}
      - run:
          name: Run tests
          command: just test-upgrade
          environment:
            FOUNDRY_FUZZ_SEED: 42424242
            FOUNDRY_FUZZ_RUNS: 1
            FOUNDRY_PROFILE: ci
            ETH_RPC_URL: <<parameters.fork_base_rpc>>
            FORK_OP_CHAIN: <<parameters.fork_op_chain>>
            FORK_BASE_CHAIN: <<parameters.fork_base_chain>>
          working_directory: packages/contracts-bedrock
          no_output_timeout: 15m
      - run:
          name: Print failed test traces
          command: |
            just test-upgrade-rerun | tee failed-test-traces.log
          environment:
            FOUNDRY_FUZZ_SEED: 42424242
            FOUNDRY_FUZZ_RUNS: 1
            FOUNDRY_PROFILE: ci
            ETH_RPC_URL: <<parameters.fork_base_rpc>>
            FORK_OP_CHAIN: <<parameters.fork_op_chain>>
            FORK_BASE_CHAIN: <<parameters.fork_base_chain>>
          working_directory: packages/contracts-bedrock
          when: on_fail
      - save_cache:
          name: Save Go build cache
          key: golang-build-cache-contracts-bedrock-tests-{{ checksum "go.sum" }}
          paths:
            - "/root/.cache/go-build"
      - save_cache:
          name: Save forked state
          key: forked-state-contracts-bedrock-tests-upgrade-<<parameters.fork_op_chain>>-<<parameters.fork_base_chain>>-{{ checksum "packages/contracts-bedrock/pinnedBlockNumber.txt" }}
          when: always
          paths:
            - "/root/.foundry/cache"
      - store_artifacts:
          path: packages/contracts-bedrock/failed-test-traces.log
          when: on_fail
      - notify-failures-on-develop

  contracts-bedrock-checks:
    machine: true
    resource_class: ethereum-optimism/latitude-1
    steps:
      - checkout-from-workspace
      - check-changed:
          patterns: contracts-bedrock
      - get-target-branch
      - run:
          name: print forge version
          command: forge --version
      - run-contracts-check:
          command: check-kontrol-summaries-unchanged
      - run-contracts-check:
          command: semgrep-test-validity-check
      - run-contracts-check:
          command: semgrep
      - run-contracts-check:
          command: semver-lock-no-build
      - run-contracts-check:
          command: semver-diff-check-no-build
      - run-contracts-check:
          command: validate-deploy-configs
      - run-contracts-check:
          command: lint
      - run-contracts-check:
          command: snapshots-check-no-build
      - run-contracts-check:
          command: interfaces-check-no-build
      - run-contracts-check:
          command: reinitializer-check-no-build
      - run-contracts-check:
          command: size-check
      - run-contracts-check:
          command: unused-imports-check-no-build
      - run-contracts-check:
          command: validate-spacers-no-build
      - run-contracts-check:
          command: opcm-upgrade-checks-no-build

  todo-issues:
    parameters:
      check_closed:
        type: boolean
        default: true
    machine:
      image: <<pipeline.parameters.base_image>>
    steps:
      - utils/checkout-with-mise
      - run:
          name: Install ripgrep
          command: sudo apt-get install -y ripgrep
      - run:
          name: Check TODO issues
          command: ./ops/scripts/todo-checker.sh --verbose --strict <<#parameters.check_closed>> --check-closed <</parameters.check_closed>>
      - notify-failures-on-develop

  fuzz-golang:
    parameters:
      package_name:
        description: Go package name
        type: string
      on_changes:
        description: changed pattern to fire fuzzer on
        type: string
      uses_artifacts:
        description: should load in foundry artifacts
        type: boolean
        default: false
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: xlarge
    steps:
      - checkout-from-workspace
      - check-changed:
          patterns: "<<parameters.package_name>>"
      - attach_workspace:
          at: "."
          if: ${{ uses_artifacts }}
      - run:
          name: Fuzz
          no_output_timeout: 15m
          command: |
            make fuzz
          working_directory: "<<parameters.package_name>>"
      - run:
          name: Copy fuzz artifacts
          command: |
            mkdir -p fuzzdata
            find ./<<parameters.package_name>> -type d -name "fuzz" -exec sh -c 'cp -r "{}"/* fuzzdata/ 2>/dev/null || true' \;
          when: always
      - store_artifacts:
          path: ./fuzzdata
          when: always

  go-lint:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: large
    steps:
      - checkout-from-workspace
      - restore_cache:
          key: golangci-v1-{{ checksum ".golangci.yaml" }}
      - run:
          name: run Go linter
          command: |
            make lint-go
      - save_cache:
          key: golangci-v1-{{ checksum ".golangci.yaml" }}
          paths:
            - "/home/circleci/.cache/golangci-lint"

  go-tests:
    parameters:
      notify:
        description: Whether to notify on failure
        type: boolean
        default: false
      mentions:
        description: Slack user or group to mention when notifying of failures
        type: string
        default: ""
      resource_class:
        description: Machine resource class
        type: string
        default: ethereum-optimism/latitude-1-go-e2e
      no_output_timeout:
        description: Timeout for when CircleCI kills the job if there's no output
        type: string
        default: 60m
      test_timeout:
        description: Timeout for running tests
        type: string
        default: 10m
      environment_overrides:
        description: Environment overrides
        type: string
        default: ""
      rule:
        description: Rule to run the tests
        type: string
        default: "go-tests-short-ci"
      parallelism:
        description: Number machines to distribute the tests across
        type: integer
        default: 1
    machine: true
    resource_class: <<parameters.resource_class>>
    circleci_ip_ranges: true
    parallelism: <<parameters.parallelism>>
    steps:
      - checkout-from-workspace
      - run:
          name: Run Go tests via Makefile
          no_output_timeout: <<parameters.no_output_timeout>>
          command: |
            <<parameters.environment_overrides>>
            export TEST_TIMEOUT=<<parameters.test_timeout>>
            make <<parameters.rule>>
      - store_test_results:
          path: ./tmp/test-results
      - run:
          name: Compress test logs
          command: |
            if [ -n "$CIRCLE_NODE_TOTAL" ] && [ "$CIRCLE_NODE_TOTAL" -gt 1 ]; then
              tar -czf testlogs-${CIRCLE_NODE_INDEX}-of-${CIRCLE_NODE_TOTAL}.tar.gz -C ./tmp testlogs
            else
              tar -czf testlogs.tar.gz -C ./tmp testlogs
            fi
          when: always
      - store_artifacts:
          path: testlogs*.tar.gz
          when: always
      - when:
          condition: "<<parameters.notify>>"
          steps:
            - notify-failures-on-develop:
                mentions: "<<parameters.mentions>>"

  go-tests-with-fault-proof-deps:
    parameters:
      notify:
        description: Whether to notify on failure
        type: boolean
        default: false
      mentions:
        description: Slack user or group to mention when notifying of failures
        type: string
        default: ""
      resource_class:
        description: Machine resource class
        type: string
        default: ethereum-optimism/latitude-1-go-e2e
      no_output_timeout:
        description: Timeout for when CircleCI kills the job if there's no output
        type: string
        default: 60m
      test_timeout:
        description: Timeout for running tests
        type: string
        default: 10m
      environment_overrides:
        description: Environment overrides
        type: string
        default: ""
    machine: true
    resource_class: <<parameters.resource_class>>
    steps:
      - checkout-from-workspace
      - run:
          name: build op-program-client
          command: make op-program-client
          working_directory: op-program
      - run:
          name: build op-program-host
          command: make op-program-host
          working_directory: op-program
      - run:
          name: build cannon
          command: make cannon
      - run:
          name: run tests
          no_output_timeout: <<parameters.no_output_timeout>>
          command: |
            <<parameters.environment_overrides>>
            export TEST_TIMEOUT=<<parameters.test_timeout>>
            make go-tests-fraud-proofs-ci
      - codecov/upload:
          disable_search: true
          files: ./coverage.out
      - store_test_results:
          path: ./tmp/test-results
      - run:
          name: Compress test logs
          command: tar -czf testlogs.tar.gz -C ./tmp testlogs
          when: always
      - store_artifacts:
          path: testlogs.tar.gz
          when: always
      - when:
          condition: "<<parameters.notify>>"
          steps:
            - notify-failures-on-develop:
                mentions: "<<parameters.mentions>>"

  op-acceptance-sync-tests-docker:
    parameters:
      gate:
        description: The gate to run the acceptance tests against. This gate should be defined in op-acceptance-tests/acceptance-tests.yaml.
        type: string
        default: ""
      no_output_timeout:
        description: Timeout for when CircleCI kills the job if there's no output
        type: string
        default: 30m
      # Optional sync test configuration parameters
      network_preset:
        description: Network preset
        type: string
        default: ""
      l2_cl_syncmode:
        description: L2 CL Sync mode - can be EL Sync or CL Sync
        type: string
        default: ""
    resource_class: xlarge
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    circleci_ip_ranges: true
    steps:
      - checkout-from-workspace
      # Restore cached Go modules
      - restore_cache:
          keys:
            - go-mod-v1-{{ checksum "go.sum" }}
            - go-mod-v1-
      # Download Go dependencies
      - run:
          name: Download Go dependencies
          working_directory: op-acceptance-tests
          command: go mod download
      - run:
          name: Lint/Vet/Build op-acceptance-tests/cmd
          working_directory: op-acceptance-tests
          command: |
            just cmd-check
      # Persist schedule name into env var
      - run:
          name: Persist schedule name into env var
          command: |
            echo 'export CIRCLECI_PIPELINE_SCHEDULE_NAME="<< pipeline.schedule.name >>"' >> $BASH_ENV
            echo 'export CIRCLECI_PARAMETERS_SYNC_TEST_OP_NODE_DISPATCH="<< pipeline.parameters.sync_test_op_node_dispatch >>"' >> $BASH_ENV
      # Run the acceptance tests
      - run:
          name: Run acceptance tests (gate=<<parameters.gate>>)
          working_directory: op-acceptance-tests
          no_output_timeout: 1h
          environment:
            GOFLAGS: "-mod=mod"
            GO111MODULE: "on"
            GOGC: "0"
            # Optional sync test configuration environment variables (only set if parameters are provided)
            NETWORK_PRESET: "<<parameters.network_preset>>"
            L2_CL_SYNCMODE: "<<parameters.l2_cl_syncmode>>"
          command: |
            # Run the tests
            LOG_LEVEL=debug just acceptance-test "" "<<parameters.gate>>"
      - run:
          name: Print results (summary)
          working_directory: op-acceptance-tests
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            cat "$LOG_DIR/summary.log" || true
      - run:
          name: Print results (failures)
          working_directory: op-acceptance-tests
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            cat "$LOG_DIR/failed/*.log" || true
          when: on_fail
      - run:
          name: Print results (all)
          working_directory: op-acceptance-tests
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            cat "$LOG_DIR/all.log" || true
      - run:
          name: Generate JUnit XML test report for CircleCI
          working_directory: op-acceptance-tests
          when: always
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            gotestsum --junitfile results/results.xml --raw-command cat $LOG_DIR/raw_go_events.log || true
      # Save the module cache for future runs
      - save_cache:
          key: go-mod-v1-{{ checksum "go.sum" }}
          paths:
            - "/go/pkg/mod"
      # Store test results and artifacts
      - when:
          condition: always
          steps:
            - store_test_results:
                path: ./op-acceptance-tests/results
      - when:
          condition: always
          steps:
            - store_artifacts:
                path: ./op-acceptance-tests/logs
      - notify-failures-on-develop:
          mentions: "@changwan <@U08L5U8070U>" # @changwan @Anton Evangelatov

  op-acceptance-tests:
    parameters:
      gate:
        description: The gate to run the acceptance tests against. This gate should be defined in op-acceptance-tests/acceptance-tests.yaml.
        type: string
        default: ""
      no_output_timeout:
        description: Timeout for when CircleCI kills the job if there's no output
        type: string
        default: 30m
      use_circleci_runner:
        description: Whether to use CircleCI runners (with Docker) instead of self-hosted runners
        type: boolean
        default: false
    machine:
      image: <<# parameters.use_circleci_runner >>ubuntu-2404:current<</ parameters.use_circleci_runner >><<^ parameters.use_circleci_runner >>true<</ parameters.use_circleci_runner >>
      docker_layer_caching: <<parameters.use_circleci_runner>>
    resource_class: <<# parameters.use_circleci_runner >>xlarge<</ parameters.use_circleci_runner >><<^ parameters.use_circleci_runner >>ethereum-optimism/latitude-1<</ parameters.use_circleci_runner >>
    steps:
      - checkout-from-workspace
      # Restore cached Go modules
      - restore_cache:
          keys:
            - go-mod-v1-{{ checksum "go.sum" }}
            - go-mod-v1-
      # Download Go dependencies
      - run:
          name: Download Go dependencies
          working_directory: op-acceptance-tests
          command: go mod download
      - run:
          name: Lint/Vet/Build op-acceptance-tests/cmd
          working_directory: op-acceptance-tests
          command: |
            just cmd-check
      # Prepare the test environment
      - run:
          name: Prepare test environment (compile tests and cache build results)
          working_directory: op-acceptance-tests
          command: go test -v -c -o /dev/null $(go list -f '{{if .TestGoFiles}}{{.ImportPath}}{{end}}' ./tests/...)
      # Run the acceptance tests (if the devnet is running)
      - run:
          name: Run acceptance tests (gate=<<parameters.gate>>)
          working_directory: op-acceptance-tests
          no_output_timeout: 1h
          command: |
            if [[ "<<parameters.gate>>" == "" ]]; then
              echo "Running in gateless mode - auto-discovering all tests in ./op-acceptance-tests/..."
            else
              echo "Running in gate mode (gate=<<parameters.gate>>)"
            fi
            LOG_LEVEL=info just acceptance-test "" "<<parameters.gate>>"
      - run:
          name: Print results (summary)
          working_directory: op-acceptance-tests
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            cat "$LOG_DIR/summary.log" || true
      - run:
          name: Print results (failures)
          working_directory: op-acceptance-tests
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            cat "$LOG_DIR/failed/*.log" || true
          when: on_fail
      - run:
          name: Print results (all)
          working_directory: op-acceptance-tests
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            cat "$LOG_DIR/all.log" || true
      - run:
          name: Generate JUnit XML test report for CircleCI
          working_directory: op-acceptance-tests
          when: always
          command: |
            LOG_DIR=$(ls -td -- logs/* | head -1)
            gotestsum --junitfile results/results.xml --raw-command cat $LOG_DIR/raw_go_events.log || true
      # Save the module cache for future runs
      - save_cache:
          key: go-mod-v1-{{ checksum "go.sum" }}
          paths:
            - "/go/pkg/mod"
      # Store test results and artifacts
      - when:
          condition: always
          steps:
            - store_test_results:
                path: ./op-acceptance-tests/results
      - when:
          condition: always
          steps:
            - store_artifacts:
                path: ./op-acceptance-tests/logs
      - when:
          condition: on_fail
          steps:
            - discord-notification-failures-on-develop:
                mentions: "Platforms (<@&1346448413172170807>) & Protocol (<@590878816004603924>)" # Protocol DevX Pod, changwan
                message: "Acceptance tests failed for gate <<parameters.gate>>"

  op-acceptance-tests-flake-shake:
    parameters:
      gate:
        type: string
        default: "flake-shake"
    machine:
      image: ubuntu-2404:current
    resource_class: large
    parallelism: << pipeline.parameters.flake-shake-workers >>
    steps:
      - checkout-from-workspace
      - restore_cache:
          keys:
            - go-mod-v1-{{ checksum "go.sum" }}
            - go-mod-v1-
      - run:
          name: Download Go dependencies
          working_directory: op-acceptance-tests
          command: go mod download
      - run:
          name: Lint/Vet/Build op-acceptance-tests/cmd
          working_directory: op-acceptance-tests
          command: |
            just cmd-check
      - run:
          name: Calculate iterations for worker
          command: |
            bash ./op-acceptance-tests/scripts/ci_flake_shake_calc_iterations.sh << pipeline.parameters.flake-shake-iterations >>
      - run:
          name: Run flake-shake iterations
          no_output_timeout: 2h
          working_directory: op-acceptance-tests
          command: |
            OUTPUT_DIR="logs/flake-shake-results-worker-${FLAKE_SHAKE_WORKER_ID}"
            mkdir -p "$OUTPUT_DIR"
            op-acceptor \
              --validators ./acceptance-tests.yaml \
              --gate << parameters.gate >> \
              --testdir tests \
              --flake-shake \
              --flake-shake-iterations "$FLAKE_SHAKE_ITERATIONS" \
              --orchestrator sysgo \
              --logdir "./$OUTPUT_DIR"
      - persist_to_workspace:
          root: op-acceptance-tests
          paths:
            - logs/flake-shake-results-worker-*/
      - store_artifacts:
          path: ./op-acceptance-tests/logs
          destination: flake-shake-workers

  op-acceptance-tests-flake-shake-report:
    machine:
      image: ubuntu-2404:current
    resource_class: large
    steps:
      - checkout-from-workspace
      - attach_workspace:
          at: .
      - run:
          name: Lint/Vet/Build op-acceptance-tests/cmd
          working_directory: op-acceptance-tests
          command: |
            just cmd-check
      - run:
          name: Build flake-shake aggregator
          working_directory: op-acceptance-tests
          command: |
            go mod download
            go build -o ../flake-shake-aggregator ./cmd/flake-shake-aggregator/main.go
      - run:
          name: Aggregate results
          command: |
            mkdir -p final-report
            ./flake-shake-aggregator \
              --input-pattern "logs/flake-shake-results-worker-*/testrun-*/flake-shake-report.json" \
              --output-dir final-report \
              --verbose
      - run:
          name: Generate summary
          command: |
            bash ./op-acceptance-tests/scripts/ci_flake_shake_generate_summary.sh final-report/flake-shake-report.json final-report
      - run:
          name: Bundle consolidated flake-shake worker logs
          command: |
            set -euo pipefail
            # Create a single tarball with all worker logs, if any exist in the workspace
            if compgen -G "op-acceptance-tests/logs/flake-shake-results-worker-*" > /dev/null; then
              tar -czf final-report/flake-shake-workers-logs.tar.gz op-acceptance-tests/logs/flake-shake-results-worker-*
              echo "Created final-report/flake-shake-workers-logs.tar.gz"
            else
              echo "No worker log directories found to bundle"
            fi
      - store_artifacts:
          path: ./final-report
          destination: flake-shake-report

  op-acceptance-tests-flake-shake-promote:
    machine:
      image: ubuntu-2404:current
    resource_class: large
    steps:
      - checkout-from-workspace
      - run:
          name: Lint/Vet/Build op-acceptance-tests/cmd
          working_directory: op-acceptance-tests
          command: |
            just cmd-check
      - run:
          name: Build flake-shake promoter
          working_directory: op-acceptance-tests
          command: |
            go mod download
            go build -o ../flake-shake-promoter ./cmd/flake-shake-promoter/main.go
      - run:
          name: Set GH_TOKEN
          command: |
            if [ -n "${GITHUB_TOKEN_GOVERNANCE:-}" ]; then
              echo "export GH_TOKEN=${GITHUB_TOKEN_GOVERNANCE}" >> "$BASH_ENV"
            fi
      - run:
          name: Validate GH_TOKEN is present
          command: |
            if [ -z "${GH_TOKEN:-}" ]; then
              echo "GH_TOKEN is required for PR creation" >&2
              exit 1
            fi
      - run:
          name: Run flake-shake promoter
          command: |
            ./flake-shake-promoter \
              --org ethereum-optimism \
              --repo optimism \
              --branch "<< pipeline.git.branch >>" \
              --workflow scheduled-flake-shake \
              --report-job op-acceptance-tests-flake-shake-report \
              --days 3 \
              --gate flake-shake \
              --min-runs 300 \
              --max-failure-rate 0.0 \
              --min-age-days 2 \
              --dry-run=false \
              --require-clean-24h \
              --out ./final-promotion \
              --verbose
      - store_artifacts:
          path: ./final-promotion
          destination: flake-shake-promotion
      - run:
          name: Prepare Slack message (promotion candidates)
          command: |
            bash ./op-acceptance-tests/scripts/ci_flake_shake_prepare_slack.sh ./final-promotion/promotion-ready.json
      - run:
          name: Slack - Sending Notification
          command: |
            set -euo pipefail
            # The Slack orb conditionals evaluate at compile time; guard at runtime instead.
            if [ -z "${SLACK_BLOCKS_PAYLOAD:-}" ] || [ "${SLACK_BLOCKS_PAYLOAD}" = "[]" ]; then
              echo "SLACK_BLOCKS is empty or doesn't exist. Skipping it..."
              exit 0
            fi
            echo "$SLACK_BLOCKS_PAYLOAD" | jq '.' > /tmp/blocks.json
            jq -c '{blocks: .}' /tmp/blocks.json > /tmp/slack_template.json
            echo 'export SLACK_TEMPLATE=$(cat /tmp/slack_template.json)' >> $BASH_ENV
      - slack/notify:
          channel: notify-ci-failures
          event: always
          retries: 1
          retry_delay: 3
          template: SLACK_TEMPLATE

  sanitize-op-program:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: large
    steps:
      - checkout-from-workspace
      - run:
          name: Install tools
          command: |
            sudo apt-get update
            sudo apt-get install -y binutils-mips-linux-gnu
      - run:
          name: Build cannon
          command: make cannon
      - run:
          name: Build op-program
          command: make op-program
      - run:
          name: Sanitize op-program client
          command: make sanitize-program GUEST_PROGRAM=../op-program/bin/op-program-client64.elf
          working_directory: cannon

  cannon-prestate-quick:
    machine: true
    resource_class: ethereum-optimism/latitude-1
    steps:
      - checkout-from-workspace
      - restore_cache:
          name: Restore cannon prestate cache
          key: cannon-prestate-{{ checksum "./cannon/bin/cannon" }}-{{ checksum "op-program/bin/op-program-client.elf" }}
      - run:
          name: Build prestates
          command: make cannon-prestates
      - save_cache:
          key: cannon-prestate-{{ checksum "./cannon/bin/cannon" }}-{{ checksum "op-program/bin/op-program-client.elf" }}
          name: Save Cannon prestate to cache
          paths:
            - "op-program/bin/prestate*.bin.gz"
            - "op-program/bin/meta*.json"
            - "op-program/bin/prestate-proof*.json"
      - persist_to_workspace:
          root: .
          paths:
            - "op-program/bin/prestate*"
            - "op-program/bin/meta*"
            - "op-program/bin/op-program"
            - "op-program/bin/op-program-client"
            - "cannon/bin"

  cannon-prestate:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    steps:
      - checkout-from-workspace
      - setup_remote_docker
      - run:
          name: Build prestates
          command: make reproducible-prestate
      - persist_to_workspace:
          root: .
          paths:
            - "op-program/bin/prestate*"
            - "op-program/bin/meta*"

  publish-cannon-prestates:
    resource_class: medium
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    steps:
      - utils/checkout-with-mise
      - attach_workspace:
          at: "."
      - gcp-cli/install
      - gcp-oidc-authenticate:
          gcp_cred_config_file_path: /tmp/gcp_cred_config.json
          oidc_token_file_path: /tmp/oidc_token.json
      - run:
          no_output_timeout: 30m
          name: Upload cannon prestates
          command: |
            # Use the actual hash for tags (hash can be found by reading releases.json)
            PRESTATE_MT64_HASH=$(jq -r .pre ./op-program/bin/prestate-proof-mt64.json)
            PRESTATE_MT64NEXT_HASH=$(jq -r .pre ./op-program/bin/prestate-proof-mt64Next.json)
            PRESTATE_INTEROP_HASH=$(jq -r .pre ./op-program/bin/prestate-proof-interop.json)
            PRESTATE_INTEROP_NEXT_HASH=$(jq -r .pre ./op-program/bin/prestate-proof-interopNext.json)

            BRANCH_NAME=$(echo "<< pipeline.git.branch >>" | tr '/' '-')
            echo "Publishing ${PRESTATE_MT64_HASH}, ${PRESTATE_MT64NEXT_HASH}, ${PRESTATE_INTEROP_HASH}, ${PRESTATE_INTEROP_NEXT_HASH} as ${BRANCH_NAME}"
            if [[ "" != "<< pipeline.git.branch >>" ]]
            then
              echo "Publishing commit hash data"
              INFO_FILE=$(mktemp)
              # Upload the git commit info for each prestate since this won't be recorded in releases.json
              (echo "Commit=<< pipeline.git.revision >>" && echo "Prestate: ${PRESTATE_MT64_HASH}") > "${INFO_FILE}"
              gsutil cp "${INFO_FILE}" "gs://oplabs-network-data/proofs/op-program/cannon/${BRANCH_NAME}-mt64.bin.gz.txt"
              echo "Published commit hash data successfully" # So we know if any uploads worked
              (echo "Commit=<< pipeline.git.revision >>" && echo "Prestate: ${PRESTATE_MT64NEXT_HASH}") > "${INFO_FILE}"
              gsutil cp "${INFO_FILE}" "gs://oplabs-network-data/proofs/op-program/cannon/${BRANCH_NAME}-mt64Next.bin.gz.txt"
              (echo "Commit=<< pipeline.git.revision >>" && echo "Prestate: ${PRESTATE_INTEROP_HASH}")  > "${INFO_FILE}"
              gsutil cp "${INFO_FILE}" "gs://oplabs-network-data/proofs/op-program/cannon/${BRANCH_NAME}-interop.bin.gz.txt"
              (echo "Commit=<< pipeline.git.revision >>" && echo "Prestate: ${PRESTATE_INTEROP_NEXT_HASH}")  > "${INFO_FILE}"
              gsutil cp "${INFO_FILE}" "gs://oplabs-network-data/proofs/op-program/cannon/${BRANCH_NAME}-interopNext.bin.gz.txt"
              rm "${INFO_FILE}" # keep things tidy
              echo "All commit info published"

              # Use the branch name for branches to provide a consistent URL
              PRESTATE_MT64_HASH="${BRANCH_NAME}-mt64"
              PRESTATE_MT64NEXT_HASH="${BRANCH_NAME}-mt64Next"
              PRESTATE_INTEROP_HASH="${BRANCH_NAME}-interop"
              PRESTATE_INTEROP_NEXT_HASH="${BRANCH_NAME}-interopNext"
            fi
            gsutil cp ./op-program/bin/prestate-mt64.bin.gz \
              "gs://oplabs-network-data/proofs/op-program/cannon/${PRESTATE_MT64_HASH}.bin.gz"

            gsutil cp ./op-program/bin/prestate-mt64Next.bin.gz \
              "gs://oplabs-network-data/proofs/op-program/cannon/${PRESTATE_MT64NEXT_HASH}.bin.gz"

            gsutil cp ./op-program/bin/prestate-interop.bin.gz \
              "gs://oplabs-network-data/proofs/op-program/cannon/${PRESTATE_INTEROP_HASH}.bin.gz"

            gsutil cp ./op-program/bin/prestate-interopNext.bin.gz \
              "gs://oplabs-network-data/proofs/op-program/cannon/${PRESTATE_INTEROP_NEXT_HASH}.bin.gz"
      - notify-failures-on-develop:
          mentions: "@proofs-team"

  preimage-reproducibility:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    steps:
      - utils/checkout-with-mise
      - setup_remote_docker
      - run:
          name: Verify reproducibility
          command: make -C op-program verify-reproducibility
      - store_artifacts:
          path: ./op-program/temp/logs
          when: always
      - notify-failures-on-develop:
          mentions: "@proofs-team"

  cannon-stf-verify:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    steps:
      - utils/checkout-with-mise
      - setup_remote_docker
      - run:
          name: Build cannon
          command: make cannon
      - run:
          name: Verify the Cannon STF
          command: make -C ./cannon cannon-stf-verify
      - notify-failures-on-develop:
          mentions: "@proofs-team"

  semgrep-scan:
    parameters:
      diff_branch:
        type: string
        default: develop
      scan_command:
        type: string
        default: semgrep ci --timeout=100
    environment:
      TEMPORARY_BASELINE_REF: << parameters.diff_branch >>
      SEMGREP_REPO_URL: << pipeline.project.git_url >>
      SEMGREP_BRANCH: << pipeline.git.branch >>
      SEMGREP_COMMIT: << pipeline.git.revision >>
    docker:
      - image: returntocorp/semgrep
    resource_class: xlarge
    steps:
      - checkout # no need to use mise here since the docker image contains the only dependency
      - unless:
          condition:
            equal: ["develop", << pipeline.git.branch >>]
          steps:
            - run:
                # Scan changed files in PRs, block on new issues only (existing issues ignored)
                # Do a full scan when scanning develop, otherwise do an incremental scan.
                name: "Conditionally set BASELINE env var"
                command: |
                  echo 'export SEMGREP_BASELINE_REF=${TEMPORARY_BASELINE_REF}' >> $BASH_ENV
      - run:
          name: "Set environment variables" # for PR comments and in-app hyperlinks to findings
          command: |
            echo 'export SEMGREP_PR_ID=${CIRCLE_PULL_REQUEST##*/}' >> $BASH_ENV
            echo 'export SEMGREP_JOB_URL=$CIRCLE_BUILD_URL' >> $BASH_ENV
            echo 'export SEMGREP_REPO_NAME=$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME' >> $BASH_ENV
      - run:
          name: "Semgrep scan"
          # --timeout (in seconds) limits the time per rule and file.
          #   SEMGREP_TIMEOUT is the same, but docs have conflicting defaults (5s in CLI flag, 1800 in some places)
          #    https://semgrep.dev/docs/troubleshooting/semgrep-app#if-the-job-is-aborted-due-to-taking-too-long
          command: << parameters.scan_command >>
          # If semgrep hangs, stop the scan after 20m, to prevent a useless 5h job
          no_output_timeout: 20m
      - notify-failures-on-develop

  bedrock-go-tests: # just a helper, that depends on all the actual test jobs
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: medium
    steps:
      - run: echo Done

  analyze-op-program-client:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: xlarge
    steps:
      - checkout-from-workspace
      - setup_remote_docker
      - run:
          name: Run Analyzer
          command: |
            make run-vm-compat
          working_directory: op-program

  op-program-compat:
    machine: true
    resource_class: ethereum-optimism/latitude-1
    steps:
      - checkout-from-workspace
      - run:
          name: Verify Compatibility
          command: |
            make verify-compat
          working_directory: op-program

  check-generated-mocks-op-node:
    machine: true
    resource_class: ethereum-optimism/latitude-1
    steps:
      - checkout-from-workspace
      - check-changed:
          patterns: op-node
      - run:
          name: check-generated-mocks
          command: make generate-mocks-op-node && git diff --exit-code

  check-generated-mocks-op-service:
    machine: true
    resource_class: ethereum-optimism/latitude-1
    steps:
      - checkout-from-workspace
      - check-changed:
          patterns: op-service
      - run:
          name: check-generated-mocks
          command: make generate-mocks-op-service && git diff --exit-code

  op-deployer-forge-version:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    steps:
      - checkout-from-workspace
      - run:
          command: just check-forge-version
          working_directory: op-deployer

  kontrol-tests:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: xlarge
    steps:
      - utils/checkout-with-mise
      - install-contracts-dependencies
      - check-changed:
          no_go_deps: "true"
          patterns: contracts-bedrock/test/kontrol,contracts-bedrock/src/L1/OptimismPortal\.sol,contracts-bedrock/src/L1/OptimismPortal2\.sol,contracts-bedrock/src/L1/L1CrossDomainMessenger\.sol,contracts-bedrock/src/L1/L1ERC721Bridge\.sol,contracts-bedrock/src/L1/L1StandardBridge\.sol,contracts-bedrock/src/L1/ResourceMetering\.sol,contracts-bedrock/src/universal/StandardBridge\.sol,contracts-bedrock/src/universal/ERC721Bridge\.sol,contracts-bedrock/src/universal/CrossDomainMessenger\.sol
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Run Kontrol Tests
          command: |
            curl -X POST \
              -H "Accept: application/vnd.github+json" \
              -H "Authorization: Bearer $RV_COMPUTE_TOKEN" \
              https://api.github.com/repos/runtimeverification/optimism-ci/actions/workflows/optimism-ci.yaml/dispatches \
              -d '{
                "ref": "master",
                "inputs": {
                  "branch_name": "<<pipeline.git.branch>>",
                  "extra_args": "script",
                  "statuses_sha": "<< pipeline.git.revision >>",
                  "org": "ethereum-optimism",
                  "repository": "optimism"
                }
              }'
          working_directory: ./packages/contracts-bedrock
      - notify-failures-on-develop

  publish-contract-artifacts:
    machine: true
    resource_class: ethereum-optimism/latitude-1
    steps:
      - gcp-cli/install
      - gcp-oidc-authenticate:
          gcp_cred_config_file_path: /tmp/gcp_cred_config.json
          oidc_token_file_path: /tmp/oidc_token.json
          project_id: GCP_TOOLS_ARTIFACTS_PROJECT_ID
          service_account_email: GCP_CONTRACTS_PUBLISHER_SERVICE_ACCOUNT_EMAIL
      - utils/checkout-with-mise
      - install-contracts-dependencies
      - run:
          name: Pull artifacts
          command: bash scripts/ops/pull-artifacts.sh
          working_directory: packages/contracts-bedrock
      - run:
          name: Build contracts
          environment:
            FOUNDRY_PROFILE: ci
          command: just forge-build
          working_directory: packages/contracts-bedrock
      - run:
          name: Publish artifacts
          command: bash scripts/ops/publish-artifacts.sh
          working_directory: packages/contracts-bedrock

  go-release:
    parameters:
      module:
        description: Go Module Name
        type: string
      filename:
        description: Goreleaser config file
        default: .goreleaser.yaml
        type: string
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: large
    steps:
      - setup_remote_docker:
          docker_layer_caching: true
      - gcp-cli/install
      - gcp-oidc-authenticate:
          gcp_cred_config_file_path: /tmp/gcp_cred_config.json
          oidc_token_file_path: /tmp/oidc_token.json
      - utils/checkout-with-mise
      - attach_workspace: { at: "." }
      - run:
          name: Configure Docker
          command: |
            gcloud auth configure-docker us-docker.pkg.dev
      - run:
          name: Run goreleaser
          command: |
            goreleaser release --clean -f ./<<parameters.module>>/<<parameters.filename>>

  diff-fetcher-forge-artifacts:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    resource_class: medium
    steps:
      - checkout-from-workspace
      - run:
          name: Build contracts
          command: |
            just build-contracts
          working_directory: op-fetcher
      - run:
          name: Compare forge artifacts
          command: |
            diff -qr "packages/contracts-bedrock/forge-artifacts/FetchChainInfo.s.sol" \
                    "op-fetcher/pkg/fetcher/fetch/forge-artifacts/FetchChainInfo.s.sol"

            if [ $? -ne 0 ]; then
              echo "ERROR: The checked-in forge artifacts for FetchChainInfo.s.sol do not match the ci build."
              echo "Please run 'just build-contracts' in the op-fetcher directory and commit the changes."
              exit 1
            fi

            echo "âœ… Checked-in forge artifacts match the ci build"

  stale-check:
    machine:
      image: ubuntu-2204:2024.08.1
    steps:
      - utils/github-stale:
          stale-issue-message: "This issue has been automatically marked as stale and will be closed in 5 days if no updates"
          stale-pr-message: "This pr has been automatically marked as stale and will be closed in 5 days if no updates"
          close-issue-message: "This issue was closed as stale.  Please reopen if this is a mistake"
          close-pr-message: "This PR was closed as stale.  Please reopen if this is a mistake"
          days-before-issue-stale: 999
          days-before-pr-stale: 14
          days-before-issue-close: 5
          days-before-pr-close: 5

  close-issue:
    machine:
      image: ubuntu-2204:2024.08.1
    parameters:
      label_name:
        type: string
      message:
        type: string
    steps:
      - github-cli/install
      - utils/github-event-handler-setup:
          github_event_base64: << pipeline.parameters.github-event-base64 >>
          env_prefix: "github_"
      - run:
          name: Close issue if label is added
          command: |
            if [ ! -z "$github_pull_request_number" ] && [ "$github_label_name" = "$LABEL_NAME" ]; then
                echo "Closing issue $github_pull_request_number as label $LABEL_NAME is added on repository ${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME} "
                export GH_TOKEN=$GITHUB_TOKEN_GOVERNANCE
                gh issue close --repo "${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}" "$github_pull_request_number" --comment "$MESSAGE"
            fi
          environment:
            MESSAGE: << parameters.message >>
            LABEL_NAME: << parameters.label_name >>

  devnet-metrics-collect-authorship:
    docker:
      - image: <<pipeline.parameters.default_docker_image>>
    steps:
      - utils/checkout-with-mise
      - run:
          name: Collect devnet metrics for op-acceptance-tests
          command: |
            ./devnet-sdk/scripts/metrics-collect-authorship.sh op-acceptance-tests/tests > .metrics--authorship--op-acceptance-tests
            echo "Wrote file .metrics--authorship--op-acceptance-tests"
      - gcp-cli/install
      - gcp-oidc-authenticate:
          gcp_cred_config_file_path: /tmp/gcp_cred_config.json
          oidc_token_file_path: /tmp/oidc_token.json
      - run:
          name: Store artifact in Bucket
          command: |
            CURRENT_DATE=$(date '+%Y-%m-%d')
            FOLDER_NAME="dt=$CURRENT_DATE"

            # Upload to the date-partitioned folder structure
            gsutil cp .metrics--authorship--op-acceptance-tests gs://oplabs-tools-data-public-metrics/metrics-authorship/$FOLDER_NAME/metrics-$CIRCLE_SHA1.csv

  generate-flaky-report:
    machine: true
    resource_class: medium
    steps:
      - utils/checkout-with-mise
      - run:
          name: Generate flaky acceptance tests report
          command: |
            # Create reports directory
            mkdir -p ./op-acceptance-tests/reports

            # Make the script executable
            chmod +x ./op-acceptance-tests/scripts/generate-flaky-tests-report.sh

            # Run the script
            ./op-acceptance-tests/scripts/generate-flaky-tests-report.sh \
              --branch "${CIRCLE_BRANCH:-develop}" \
              --org "${CIRCLE_PROJECT_USERNAME}" \
              --repo "${CIRCLE_PROJECT_REPONAME}" \
              --token "${CIRCLE_API_TOKEN}" \
              --output-dir "./op-acceptance-tests/reports"

      # Store the flaky test reports
      - store_artifacts:
          path: ./op-acceptance-tests/reports
          destination: flaky-test-reports

workflows:
  # Nightly Kurtosis acceptance tests
  scheduled-kurtosis-acceptance-tests:
    when:
      or:
        - equal: [build_daily, <<pipeline.schedule.name>>]
        - and:
            - equal: [true, << pipeline.parameters.kurtosis_acceptance_tests_dispatch >>]
            - equal: ["api", << pipeline.trigger_source >>]
    jobs:
      - initialize:
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-build: # needed for in-process tests that some suites may use
          build_args: --skip test
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - cannon-prestate-quick: # needed for sysgo tests (if any package is in-memory)
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - op-acceptance-tests-kurtosis:
          name: kurtosis-simple-nightly
          devnet: simple
          gate: base
          use_circleci_runner: true
          no_output_timeout: 60m
          context:
            - circleci-repo-readonly-authenticated-github-token
            - discord
          requires:
            - contracts-bedrock-build
            - cannon-prestate-quick
      - op-acceptance-tests-kurtosis:
          name: kurtosis-jovian-nightly
          devnet: jovian
          gate: jovian
          use_circleci_runner: true
          no_output_timeout: 60m
          context:
            - circleci-repo-readonly-authenticated-github-token
            - discord
          requires:
            - contracts-bedrock-build
            - cannon-prestate-quick
      - op-acceptance-tests-kurtosis:
          name: kurtosis-interop-nightly
          devnet: interop
          gate: interop
          use_circleci_runner: true
          no_output_timeout: 60m
          context:
            - circleci-repo-readonly-authenticated-github-token
            - discord
          requires:
            - contracts-bedrock-build
            - cannon-prestate-quick
  main:
    when:
      or:
        - equal: ["webhook", << pipeline.trigger_source >>]
        - and:
            - equal: [true, <<pipeline.parameters.main_dispatch>>]
            - equal: ["api", << pipeline.trigger_source >>]
            - equal: [
                  << pipeline.parameters.github-event-type >>,
                  "__not_set__",
                ] #this is to prevent triggering this workflow as the default value is always set for main_dispatch
    jobs:
      - initialize:
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-build:
          name: contracts-bedrock-build
          # Build with just core + script contracts.
          build_args: --deny-warnings --skip test
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - check-kontrol-build:
          requires:
            - contracts-bedrock-build
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-tests:
          # Test everything except PreimageOracle.t.sol since it's slow.
          name: contracts-bedrock-tests
          test_list: find test -name "*.t.sol" -not -name "PreimageOracle.t.sol"
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
          check_changed_patterns: contracts-bedrock,op-node
      - contracts-bedrock-tests:
          # PreimageOracle test is slow, run it separately to unblock CI.
          name: contracts-bedrock-tests-preimage-oracle
          test_list: find test -name "PreimageOracle.t.sol"
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - contracts-bedrock-tests:
          # Heavily fuzz any fuzz tests within added or modified test files.
          name: contracts-bedrock-tests-heavy-fuzz-modified
          test_list: git diff origin/develop...HEAD --name-only --diff-filter=AM -- './test/**/*.t.sol' | sed 's|packages/contracts-bedrock/||'
          test_timeout: 1h
          test_profile: ciheavy
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - contracts-bedrock-coverage:
          # Generate coverage reports.
          name: contracts-bedrock-coverage <<matrix.dev_features>>
          test_timeout: 1h
          test_profile: cicoverage
          dev_features: <<matrix.dev_features>>
          matrix:
            parameters:
              dev_features: ["main", "OPTIMISM_PORTAL_INTEROP","CANNON_KONA","CANNON_KONA,DEPLOY_V2_DISPUTE_GAMES"]
          # need this requires to ensure that all FFI JSONs exist
          requires:
            - contracts-bedrock-build
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-tests-upgrade:
          name: contracts-bedrock-tests-upgrade <<matrix.fork_op_chain>>-mainnet
          fork_op_chain: <<matrix.fork_op_chain>>
          fork_base_chain: mainnet
          fork_base_rpc: https://ci-mainnet-l1-archive.optimism.io
          matrix:
            parameters:
              fork_op_chain: ["op", "base", "ink", "unichain"]
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - contracts-bedrock-checks:
          requires:
            - contracts-bedrock-build
          context:
            - circleci-repo-readonly-authenticated-github-token
      - diff-fetcher-forge-artifacts:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - contracts-bedrock-build
      - op-deployer-forge-version:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - diff-asterisc-bytecode:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - semgrep-scan:
          name: semgrep-scan-local
          scan_command: semgrep scan --timeout=100 --config .semgrep/rules/ --error .
          context:
            - slack
            - circleci-repo-readonly-authenticated-github-token
      - semgrep-scan:
          name: semgrep-test
          scan_command: semgrep scan --test --config .semgrep/rules/ .semgrep/tests/
          context:
            - slack
            - circleci-repo-readonly-authenticated-github-token
      - go-lint:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - fuzz-golang:
          name: fuzz-golang-<<matrix.package_name>>
          on_changes: <<matrix.package_name>>
          matrix:
            parameters:
              package_name:
                - op-challenger
                - op-node
                - op-service
                - op-chain-ops
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - fuzz-golang:
          name: cannon-fuzz
          package_name: cannon
          on_changes: cannon,packages/contracts-bedrock/src/cannon
          uses_artifacts: true
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - contracts-bedrock-build
      - fuzz-golang:
          name: op-e2e-fuzz
          package_name: op-e2e
          on_changes: op-e2e,packages/contracts-bedrock/src
          uses_artifacts: true
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - contracts-bedrock-build
      - go-tests:
          name: go-tests-short
          parallelism: 4
          no_output_timeout: 19m
          test_timeout: 20m
          requires:
            - contracts-bedrock-build
            - cannon-prestate-quick
          context:
            - circleci-repo-readonly-authenticated-github-token
          filters:
            branches:
              ignore: develop # Run on all branches EXCEPT develop (PR branches only)
      - go-tests:
          name: go-tests-full
          rule: "go-tests-ci" # Run full test suite instead of short
          parallelism: 4
          no_output_timeout: 89m # Longer timeout for full tests
          test_timeout: 90m
          notify: true
          filters:
            branches:
              only: develop # Only runs on develop branch (post-merge)
          requires:
            - contracts-bedrock-build
            - cannon-prestate-quick
          context:
            - circleci-repo-readonly-authenticated-github-token
            - slack
      - analyze-op-program-client:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - op-program-compat:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - bedrock-go-tests:
          requires:
            - go-lint
            - cannon-go-lint-and-test
            - check-generated-mocks-op-node
            - check-generated-mocks-op-service
            - op-program-compat
            # Not needed for the devnet but we want to make sure they build successfully
            - cannon-docker-build
            - op-dispute-mon-docker-build
            - op-program-docker-build
            - op-supervisor-docker-build
            - op-test-sequencer-docker-build
            - go-tests-short
            - sanitize-op-program
          context:
            - circleci-repo-readonly-authenticated-github-tokens
      - docker-build:
          name: <<matrix.docker_name>>-docker-build
          docker_tags: <<pipeline.git.revision>>,<<pipeline.git.branch>>
          save_image_tag: <<pipeline.git.revision>>
          matrix:
            parameters:
              docker_name:
                - op-node
                - op-batcher
                - op-faucet
                - op-program
                - op-proposer
                - op-challenger
                - op-dispute-mon
                - op-deployer
                - op-conductor
                - da-server
                - op-supervisor
                - op-test-sequencer
                - cannon
                - op-dripper
                - op-interop-mon
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
            - contracts-bedrock-build
      - cannon-prestate-quick:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - sanitize-op-program:
          requires:
            - cannon-prestate-quick
          context:
            - circleci-repo-readonly-authenticated-github-token
      - check-generated-mocks-op-node:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - check-generated-mocks-op-service:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - cannon-go-lint-and-test:
          requires:
            - contracts-bedrock-build
          skip_slow_tests: true
          notify: true
          context:
            - circleci-repo-readonly-authenticated-github-token
      - todo-issues:
          name: todo-issues-check
          check_closed: false
          context:
            - circleci-repo-readonly-authenticated-github-token
      - shellcheck/check:
          name: shell-check
          # We don't need the `exclude` key as the orb detects the `.shellcheckrc`
          dir: .
          ignore-dirs: ./packages/contracts-bedrock/lib
          context:
            - circleci-repo-readonly-authenticated-github-token

  go-release-op-deployer:
    jobs:
      - initialize:
          filters:
            tags:
              only: /^op-deployer.*/
            branches:
              ignore: /.*/
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-build:
          name: build-contracts-go-release-op-deployer
          filters:
            tags:
              only: /^op-deployer.*/
            branches:
              ignore: /.*/
          build_args: --skip test
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - go-release:
          filters:
            tags:
              only: /^op-deployer.*/
            branches:
              ignore: /.*/
          module: op-deployer
          context:
            - oplabs-gcr-release
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - build-contracts-go-release-op-deployer

  go-release-op-up:
    jobs:
      - initialize:
          filters:
            tags:
              only: /^op-up.*/
            branches:
              ignore: /.*/
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-build:
          name: build-contracts-go-release-op-up
          filters:
            tags:
              only: /^op-up.*/
            branches:
              ignore: /.*/
          build_args: --skip test
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - go-release:
          filters:
            tags:
              only: /^op-up.*/
            branches:
              ignore: /.*/
          module: op-up
          context:
            - oplabs-gcr-release
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - build-contracts-go-release-op-up

  release:
    when:
      not:
        equal: [scheduled_pipeline, << pipeline.trigger_source >>]
    jobs:
      - initialize:
          context:
            - circleci-repo-readonly-authenticated-github-token
          filters:
            tags:
              only: /^(da-server|cannon|ufm-[a-z0-9\-]*|op-[a-z0-9\-]*)\/v.*/
            branches:
              ignore: /.*/
      - contracts-bedrock-build:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      # Standard (medium) cross-platform docker images go here
      - docker-build:
          matrix:
            parameters:
              docker_name:
                - op-node
                - op-batcher
                - op-faucet
                - op-proposer
                - op-challenger
                - op-dispute-mon
                - op-conductor
                - da-server
                - op-ufm
                - op-supervisor
                - op-test-sequencer
                - op-deployer
                - cannon
                - op-dripper
                - op-interop-mon
          name: <<matrix.docker_name>>-docker-release
          docker_tags: <<pipeline.git.revision>>
          platforms: "linux/amd64,linux/arm64"
          publish: true
          release: true
          filters:
            tags:
              only: /^<<matrix.docker_name>>\/v.*/
            branches:
              ignore: /.*/
          context:
            - oplabs-gcr-release
          requires:
            - initialize
            - contracts-bedrock-build
      # Checks for cross-platform images go here
      - check-cross-platform:
          matrix:
            parameters:
              op_component:
                - op-node
                - op-batcher
                - op-faucet
                - op-proposer
                - op-challenger
                - op-dispute-mon
                - op-conductor
                - da-server
                - op-ufm
                - op-supervisor
                - op-test-sequencer
                - op-deployer
                - cannon
                - op-dripper
                - op-interop-mon
          name: <<matrix.op_component>>-cross-platform
          requires:
            - op-node-docker-release
            - op-batcher-docker-release
            - op-faucet-docker-release
            - op-proposer-docker-release
            - op-challenger-docker-release
            - op-dispute-mon-docker-release
            - op-conductor-docker-release
            - da-server-docker-release
            - op-ufm-docker-release
            - op-supervisor-docker-release
            - op-test-sequencer-docker-release
            - cannon-docker-release
            - op-dripper-docker-release
            - op-interop-mon-docker-release
          context:
            - circleci-repo-readonly-authenticated-github-token
      - cannon-prestate:
          filters:
            tags:
              only: /^op-program\/v.*/
            branches:
              ignore: /.*/
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - publish-cannon-prestates:
          context:
            - circleci-repo-readonly-authenticated-github-token
            - slack
            - oplabs-network-optimism-io-bucket
          requires:
            - cannon-prestate
          filters:
            tags:
              only: /^op-program\/v.*/
            branches:
              ignore: /.*/

  scheduled-todo-issues:
    when:
      equal: [build_four_hours, <<pipeline.schedule.name>>]
    jobs:
      - todo-issues:
          name: todo-issue-checks
          context:
            - slack
            - circleci-repo-readonly-authenticated-github-token

  develop-publish-contract-artifacts:
    when:
      or:
        - and:
            - equal: ["develop", <<pipeline.git.branch>>]
            - equal: ["webhook", << pipeline.trigger_source >>]
        - and:
            - equal:
                [
                  true,
                  <<pipeline.parameters.publish_contract_artifacts_dispatch>>,
                ]
            - equal: ["api", << pipeline.trigger_source >>]
    jobs:
      - publish-contract-artifacts:
          context:
            - circleci-repo-readonly-authenticated-github-token

  develop-fault-proofs:
    when:
      or:
        - and:
            - equal: ["develop", <<pipeline.git.branch>>]
            - equal: ["webhook", << pipeline.trigger_source >>]
        - and:
            - equal: [true, <<pipeline.parameters.fault_proofs_dispatch>>]
            - equal: ["api", << pipeline.trigger_source >>]
    jobs:
      - initialize:
          context:
            - circleci-repo-readonly-authenticated-github-token
      - cannon-prestate:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - cannon-stf-verify:
          context:
            - slack
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-build:
          build_args: --deny-warnings --skip test
          context:
            - slack
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - go-tests-with-fault-proof-deps:
          name: op-e2e-cannon-tests
          notify: true
          mentions: "@proofs-team"
          no_output_timeout: 90m
          test_timeout: 480m
          resource_class: ethereum-optimism/latitude-fps-1
          context:
            - slack
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - contracts-bedrock-build
            - cannon-prestate
      - publish-cannon-prestates:
          context:
            - slack
            - oplabs-network-optimism-io-bucket
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - cannon-prestate
            - op-e2e-cannon-tests

  develop-kontrol-tests:
    when:
      or:
        - and:
            - equal: ["develop", <<pipeline.git.branch>>]
            - equal: ["webhook", << pipeline.trigger_source >>]
        - and:
            - equal: [true, <<pipeline.parameters.kontrol_dispatch>>]
            - equal: ["api", << pipeline.trigger_source >>]
    jobs:
      - kontrol-tests:
          context:
            - slack
            - runtimeverification
            - circleci-repo-readonly-authenticated-github-token

  scheduled-cannon-full-tests:
    when:
      or:
        - equal: [build_four_hours, <<pipeline.schedule.name>>]
        - equal: [true, << pipeline.parameters.cannon_full_test_dispatch >>]
    jobs:
      - initialize:
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-build:
          build_args: --deny-warnings --skip test
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - cannon-go-lint-and-test:
          requires:
            - contracts-bedrock-build
          skip_slow_tests: false
          no_output_timeout: 30m
          notify: true
          context:
            - slack
            - circleci-repo-readonly-authenticated-github-token

  scheduled-docker-publish:
    when:
      or:
        - equal: [build_daily, <<pipeline.schedule.name>>]
        # Trigger on manual triggers if explicitly requested
        - equal: [true, << pipeline.parameters.docker_publish_dispatch >>]
    jobs:
      - initialize:
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-build:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - docker-build:
          matrix:
            parameters:
              docker_name:
                - op-node
                - op-batcher
                - op-deployer
                - op-faucet
                - op-program
                - op-proposer
                - op-challenger
                - op-dispute-mon
                - op-conductor
                - op-supervisor
                - op-test-sequencer
                - cannon
                - op-dripper
                - op-interop-mon
          name: <<matrix.docker_name>>-docker-publish
          docker_tags: <<pipeline.git.revision>>,<<pipeline.git.branch>>
          platforms: "linux/amd64,linux/arm64"
          publish: true
          context:
            - oplabs-gcr
            - slack
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
            - contracts-bedrock-build
      - check-cross-platform:
          matrix:
            parameters:
              op_component:
                - op-node
                - op-batcher
                - op-deployer
                - op-faucet
                - op-program
                - op-proposer
                - op-challenger
                - op-dispute-mon
                - op-conductor
                - op-supervisor
                - op-test-sequencer
                - cannon
                - op-dripper
                - op-interop-mon
          name: <<matrix.op_component>>-cross-platform
          requires:
            - <<matrix.op_component>>-docker-publish
          context:
            - circleci-repo-readonly-authenticated-github-token

  scheduled-flake-shake:
    when:
      or:
        - equal: [build_daily, << pipeline.schedule.name >>]
        - and:
            - equal: [true, << pipeline.parameters.flake-shake-dispatch >>]
            - equal: ["api", << pipeline.trigger_source >>]
    jobs:
      - initialize:
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-build:
          build_args: --skip test
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - cannon-prestate-quick:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - op-acceptance-tests-flake-shake:
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - contracts-bedrock-build
            - cannon-prestate-quick
      - op-acceptance-tests-flake-shake-report:
          requires:
            - op-acceptance-tests-flake-shake
      - op-acceptance-tests-flake-shake-promote:
          requires:
            - op-acceptance-tests-flake-shake-report
          context:
            - circleci-repo-readonly-authenticated-github-token
            - circleci-repo-optimism
            - circleci-api-token
            - slack

  scheduled-preimage-reproducibility:
    when:
      or:
        - equal: [build_daily, <<pipeline.schedule.name>>]
        # Trigger on manual triggers if explicitly requested
        - equal: [true, << pipeline.parameters.reproducibility_dispatch >>]
    jobs:
      - preimage-reproducibility:
          context:
            - slack
            - circleci-repo-readonly-authenticated-github-token

  scheduled-stale-check:
    when:
      or:
        - equal: [build_daily, <<pipeline.schedule.name>>]
          # Trigger on manual triggers if explicitly requested
        - equal: [true, << pipeline.parameters.stale_check_dispatch >>]
    jobs:
      - stale-check:
          context:
            - circleci-repo-optimism

  scheduled-sync-test-op-node:
    when:
      or:
        - equal: [build_daily, <<pipeline.schedule.name>>]
        # Trigger on manual triggers if explicitly requested
        - equal: [true, << pipeline.parameters.sync_test_op_node_dispatch >>]
    jobs:
      - initialize:
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-build: # needed for sysgo tests
          build_args: --skip test
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - cannon-prestate-quick: # needed for sysgo tests
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - op-acceptance-sync-tests-docker:
          name: "sync-test-<<matrix.network_preset>>-daily-<<matrix.l2_cl_syncmode>>"
          gate: sync-test-op-node
          no_output_timeout: 30m
          context:
            - circleci-repo-readonly-authenticated-github-token
            - discord
          requires:
            - contracts-bedrock-build
            - cannon-prestate-quick
          matrix:
            parameters:
              network_preset: ["op-sepolia", "base-sepolia", "unichain-sepolia", "op-mainnet", "base-mainnet"]
              l2_cl_syncmode: ["consensus-layer", "execution-layer"]

  scheduled-heavy-fuzz-tests:
    when:
      or:
        - equal: [build_daily, <<pipeline.schedule.name>>]
        - equal: [true, << pipeline.parameters.heavy_fuzz_dispatch >>]
    jobs:
      - initialize:
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-heavy-fuzz-nightly:
          context:
            - slack
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize

  # Acceptance tests
  acceptance-tests:
    when:
      or:
        - equal: ["webhook", << pipeline.trigger_source >>]
        # Manual dispatch
        - and:
            - equal: [true, <<pipeline.parameters.acceptance_tests_dispatch>>]
            - equal: ["api", << pipeline.trigger_source >>]
    jobs:
      - initialize:
          context:
            - circleci-repo-readonly-authenticated-github-token
      - contracts-bedrock-build: # needed for sysgo tests
          build_args: --skip test
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      - cannon-prestate-quick: # needed for sysgo tests
          context:
            - circleci-repo-readonly-authenticated-github-token
          requires:
            - initialize
      # IN-MEMORY (all)
      - op-acceptance-tests:
          name: memory-all
          gate: "" # Empty gate = gateless mode
          no_output_timeout: 90m
          context:
            - circleci-repo-readonly-authenticated-github-token
            - discord
          requires:
            - contracts-bedrock-build
            - cannon-prestate-quick
      # Generate flaky test report
      - generate-flaky-report:
          name: generate-flaky-tests-report
          context:
            - circleci-repo-readonly-authenticated-github-token
            - circleci-api-token

  close-issue-workflow:
    when:
      and:
        - equal: [<< pipeline.trigger_source >>, "api"]
        - equal: [<< pipeline.parameters.github-event-type >>, "pull_request"]
        - equal: [<< pipeline.parameters.github-event-action >>, "labeled"]
    jobs:
      - close-issue:
          label_name: "auto-close-trivial-contribution"
          message: "Thank you for your interest in contributing!
            At this time, we are not accepting contributions that primarily fix spelling, stylistic, or grammatical errors in documentation, code, or elsewhere.
            Please check our [contribution guidelines](https://github.com/ethereum-optimism/optimism/blob/develop/CONTRIBUTING.md#contributions-related-to-spelling-and-grammar) for more information.
            This issue will be closed now."
          context:
            - circleci-repo-optimism

  devnet-metrics-collect:
    when:
      or:
        - equal: [<< pipeline.trigger_source >>, "webhook"]
        - and:
            - equal: [true, << pipeline.parameters.devnet-metrics-collect >>]
            - equal: [<< pipeline.trigger_source >>, "api"]
    jobs:
      - devnet-metrics-collect-authorship:
          context:
            - circleci-repo-readonly-authenticated-github-token
            - oplabs-tools-data-public-metrics-bucket

  ai-contracts-test-workflow:
    when:
      or:
        - equal: [build_mon_thu, <<pipeline.schedule.name>>]
        - equal: [true, << pipeline.parameters.ai_contracts_test_dispatch >>]
    jobs:
      - initialize:
          context:
            - circleci-repo-readonly-authenticated-github-token
      - ai-contracts-test:
          context:
            - circleci-repo-readonly-authenticated-github-token
            - circleci-api-token
            - devin-api
          requires:
            - initialize
